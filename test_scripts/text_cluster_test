# This Python file uses the following encoding: utf-8
import MySQLdb
import math
import numpy as np

import pylab as pl
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer
from sklearn.cluster import KMeans, MiniBatchKMeans
from sklearn import metrics
from numpy.random import RandomState
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics.pairwise import euclidean_distances
import json



def my_query(connection, q):
	cursor = connection.cursor()
	cursor.execute(q)
	return cursor.fetchall()

conn = MySQLdb.connect(host='localhost', user='root', passwd='ct123690')
doc_q = "SELECT * FROM clustering.particle"
doc_rows = my_query(conn, doc_q)

document_data = []
myLabel = []
for i, row in enumerate(doc_rows):
	document_data.insert(i, (row[1] + ' ' + row[2]).decode('latin-1')) # + row[3]
	myLabel.insert(i, row[3])

vectorizer = CountVectorizer(
	# max_df=1.095
	max_df=0.95,
	# min_df=2,
	# ngram_range=(2, 2),
	# vocabulary=myVoca,
	# max_features=2500,
	stop_words='english'
)

transformer = TfidfTransformer()
X_counts = vectorizer.fit_transform(document_data)
X_tfidf = transformer.fit_transform(X_counts)
# print vectorizer.get_feature_names()
km = KMeans(n_clusters=10, init='k-means++', max_iter=100, n_init=1, verbose=False, random_state=RandomState(42))
X_kmean = km.fit(X_tfidf)
# print len(X_kmean.cluster_centers_[0])

X_kmean_r = X_kmean.transform(X_tfidf)
cluster_centers_r = X_kmean.transform(X_kmean.cluster_centers_)
print(cluster_centers_r)

number_of_centers = len(cluster_centers_r)-1

#生成tuple with 两两组合并去掉反向重复
list1 = np.linspace(0, number_of_centers, number_of_centers+1).astype(int)
list2 = np.linspace(0, number_of_centers, number_of_centers+1).astype(int)
new_list = [(x, y) for x in list1 for y in list2 if x != y]
list3 = list(set(tuple(sorted((a, b))) for a, b in new_list))

#生成links
links = [
	(x, y, math.pow(1/euclidean_distances(cluster_centers_r[x], cluster_centers_r[y], squared=True)[0][0], 2))
	for i, (x, y) in enumerate(list3)
	if math.pow(1/euclidean_distances(cluster_centers_r[x], cluster_centers_r[y], squared=True)[0][0], 2) > 5
]
print links

#生成nodes
nodes = [(x, sum(X_kmean.labels_ == x)) for x in list1 if x != 0]
print nodes

#生成nodes links object
nodesdict = {
	"nodes": [{"name": node, "group": node, "size": size} for node, size in nodes],
	"links": [{"source": source, "target": target, "value": value} for source, target, value in links]

}
print nodesdict

#create json
nodesdict_josn = json.dumps(nodesdict, indent=5)